{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b1de13",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Describe the structure of an artificial neuron. How is it similar to a biological neuron? What are its main components?\n",
    "Ans: Artificial neuron also known as perceptron is the basic unit of the neural network. In simple terms, it is a mathematical\n",
    "    function based on a model of biological neurons. It can also be seen as a simple logic gate with binary outputs. They are \n",
    "    sometimes also called perceptrons.\n",
    "    An artificial neuron is a connection point in an artificial neural network. Artificial neural networks, like the human \n",
    "    body's biological neural network, have a layered architecture and each network node (connection point) has the capability \n",
    "    to process input and forward output to other nodes in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6657e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. What are the different types of activation functions popularly used? Explain each of them.\n",
    "Ans: 1. Binary Step Function\n",
    "The first thing that comes to our mind when we have an activation function would be a threshold based classifier i.e. whether \n",
    "or not the neuron should be activated based on the value from the linear transformation.\n",
    "2. Linear Function\n",
    "We saw the problem with the step function, the gradient of the function became zero. This is because there is no component of x\n",
    "in the binary step function. Instead of a binary function, we can use a linear function.\n",
    "3. Sigmoid\n",
    "The next activation function that we are going to look at is the Sigmoid function. It is one of the most widely used non-linear\n",
    "activation function. Sigmoid transforms the values between the range 0 and 1.\n",
    "4. Tanh\n",
    "The tanh function is very similar to the sigmoid function. The only difference is that it is symmetric around the origin. The range of values in this case is from -1 to 1. Thus the inputs to the next layers will not always be of the same sign. \n",
    "5. ReLU\n",
    "The ReLU function is another non-linear activation function that has gained popularity in the deep learning domain. ReLU stands for Rectified Linear Unit. The main advantage of using the ReLU function over other activation functions is that it does not activate all the neurons at the same time.\n",
    "6. Leaky ReLU\n",
    "Leaky ReLU function is nothing but an improved version of the ReLU function. As we saw that for the ReLU function, the gradient is 0 for x<0, which would deactivate the neurons in that region.\n",
    "7. Parameterised ReLU\n",
    "This is another variant of ReLU that aims to solve the problem of gradient’s becoming zero for the left half of the axis. The parameterised ReLU, as the name suggests, introduces a new parameter as a slope of the negative part of the function.\n",
    "8. Exponential Linear Unit\n",
    "Exponential Linear Unit or ELU for short is also a variant of Rectiufied Linear Unit (ReLU) that modifies the slope of the negative part of the function. Unlike the leaky relu and parametric ReLU functions, instead of a straight line, ELU uses a log curve for defning the negatice values. \n",
    "9.Swish\n",
    "Swish is a lesser known activation function which was discovered by researchers at Google. Swish is as computationally efficient as ReLU and shows better performance than ReLU on deeper models.  The values for swish ranges from negative infinity to infinity.\n",
    "10. Softmax\n",
    "Softmax function is often described as a combination of multiple sigmoids. We know that sigmoid returns values between 0 and 1, which can be treated as probabilities of a data point belonging to a particular class. Thus sigmoid is widely used for binary classification problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5709271",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Explain the basic structure of a multi-layer perceptron. Explain how it can solve the XOR problem.\n",
    "Ans: The XOR problem with neural networks can be solved by using Multi-Layer Perceptrons or a neural network architecture with \n",
    "    an input layer, hidden layer, and output layer. So during the forward propagation through the neural networks, the weights \n",
    "    get updated to the corresponding layers and the XOR logic gets executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fb8a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. What is artificial neural network (ANN)? Explain some of the salient highlights in the different architectural options for \n",
    "ANN.\n",
    "Ans: Artificial Neural Network Tutorial provides basic and advanced concepts of ANNs. Our Artificial Neural Network tutorial is \n",
    "    developed for beginners as well as professions.\n",
    "\n",
    "The term \"Artificial neural network\" refers to a biologically inspired sub-field of artificial intelligence modeled after the \n",
    "brain. An Artificial neural network is usually a computational network based on biological neural networks that construct the \n",
    "structure of the human brain. Similar to a human brain has neurons interconnected to each other, artificial neural networks \n",
    "also have neurons that are linked to each other in various layers of the networks. These neurons are known as nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830f54f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Explain the learning process of an ANN. Explain, with example, the challenge in assigning synaptic weights for the \n",
    "interconnection between neurons? How can this challenge be addressed?\n",
    "Ans: ANN is a computational system consisting of many interconnected units called artificial neurons. The connection between artificial neurons can transmit a signal from one neuron to another. So, there are multiple possibilities for connecting the neurons based on which the architecture we are going to adopt for a specific solution. Some permutations and combinations are as follows: \n",
    "\n",
    "There may be just two layers of neuron in the network – the input and output layer.\n",
    "There can be one or more intermediate ‘hidden’ layers of a neuron.\n",
    "The neurons may be connected with all neurons in the next layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aac4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. Explain, in details, the backpropagation algorithm. What are the limitations of this algorithm?\n",
    "Ans: Backpropagation, or backward propagation of errors, is an algorithm that is designed to test for errors working back from \n",
    "    output nodes to input nodes. It is an important mathematical tool for improving the accuracy of predictions in data mining \n",
    "    and machine learning.\n",
    "    Limitations of the Backpropagation algorithm: It is slow, all previous layers are locked until gradients for the current \n",
    "        layer is calculated. It suffers from vanishing or exploding gradients problem. It suffers from overfitting & \n",
    "        underfitting problem.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c24f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Describe, in details, the process of adjusting the interconnection weights in a multi-layer neural network.\n",
    "Ans: The backpropagation algorithm is applicable for multi-layer feed-forward network. It is a supervised learning algorithm \n",
    "    which continues adjusting the weights of the connected neurons with an objective to reduce the deviation of the output \n",
    "    signal from the target output. This algorithm consists of multiple iterations, known as epochs. Each epoch consists of two \n",
    "    phases:\n",
    "\n",
    "Forward Phase: Signal flow from neurons in the input layer to the neurons in the output layer through the hidden layers.\n",
    "    The weights of the interconnections and activation functions are used during the flow. In the output layer, the output \n",
    "    signals are generated.\n",
    "Backward Phase: Signal is compared with the expected value. The computed errors are propagated backwards from the output to the\n",
    "    preceding layer. The error propagated back are used to adjust the interconnection weights between the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9405baa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. What are the steps in the backpropagation algorithm? Why a multi-layer neural network is required?\n",
    "Ans: The steps involved in Backpropagation:\n",
    "\n",
    "Step – 1: Forward Propagation\n",
    "Step – 2: Backward Propagation \n",
    "Step – 3: Putting all the values together and calculating the updated weight value\n",
    "    There is a theoretical result which says that an MLP with only one hidden layer can fit every function of interest up to an\n",
    "    arbitrary low error margin if this hidden layer has enough neurons. However, the number of parameters might be MUCH larger \n",
    "    than if you add more layers.\n",
    "\n",
    "Basically, by adding more hidden layers / more neurons per layer you add more parameters to the model. Hence you allow the \n",
    "model to fit more complex functions. However, up to my knowledge there is no quantitative understanding what adding a single \n",
    "further layer / node exactly makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d237f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. Write short notes on:\n",
    "Artificial neuron\n",
    "Multi-layer perceptron\n",
    "Deep learning\n",
    "Learning rate\n",
    "Ans: Artificial neuron: An artificial neuron is a connection point in an artificial neural network. Artificial neural networks,\n",
    "        like the human body's biological neural network, have a layered architecture and each network node (connection point) \n",
    "        has the capability to process input and forward output to other nodes in the network.\n",
    "    Multi-layer perceptron : Multi-layer perception is also known as MLP. It is fully connected dense layers, which transform \n",
    "        any input dimension to the desired dimension. A multi-layer perception is a neural network that has multiple layers. \n",
    "        To create a neural network we combine neurons together so that the outputs of some neurons are inputs of other neurons.\n",
    "    Deep learning : Deep learning is a subset of machine learning, which is essentially a neural network with three or more \n",
    "        layers. These neural networks attempt to simulate the behavior of the human brain—albeit far from matching its \n",
    "        ability—allowing it to “learn” from large amounts of data.\n",
    "    Learning rate: In machine learning and statistics, the learning rate is a tuning parameter in an optimization algorithm \n",
    "        that determines the step size at each iteration while moving toward a minimum of a loss function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
