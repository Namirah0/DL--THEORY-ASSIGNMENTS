{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bada7f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What is the function of a summation junction of a neuron? What is threshold activation function ?\n",
    "Ans: The biological neural network has been modeled in the form of Artificial Neural Networks with artificial neurons \n",
    "    simulating the function of a biological neuron.\n",
    "    There are different types of activation functions. The most commonly used activation function are listed below:\n",
    "        A. Identity Function:\n",
    "        B. Threshold/step Function\n",
    "        C. ReLU (Rectified Linear Unit) Function\n",
    "        D. Sigmoid Function\n",
    "Threshold/step Function: It is a commonly used activation function. As depicted in the diagram, it gives 1 as output of\n",
    "the input is either 0 or positive. If the input is negative, it gives 0 as output. Expressing it mathematically, \n",
    "\n",
    "    y_{out}=f(y_{sum})=\\bigg\\{\\begin{matrix} 1, x \\geq 0 \\\\ 0, x < 0 \\end{matrix}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca8d882",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. What is a step function? What is the difference of step function with threshold function ?\n",
    "Ans: A step function is a function like that used by the original Perceptron. The output is a certain value, A1, if the input\n",
    "    sum is above a certain threshold and A0 if the input sum is below a certain threshold. The values used by the Perceptron \n",
    "    were A1 = 1 and A0 = 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9199132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Explain the McCulloch–Pitts model of neuron ?\n",
    "Ans: The motivation behind the McCulloh Pitt's Model is a biological neuron. A biological neuron takes an input signal from the\n",
    "    dendrites and after processing it passes onto other connected neurons as the output if the signal is received positively, \n",
    "    through axons and synapses.\n",
    "    The McCulloch–Pitt neural network is considered to be the first neural network. The neurons are connected by directed \n",
    "    weighted paths. McCulloch–Pitt neuron allows binary activation (1 ON or 0 OFF), i.e., it either fires with an activation 1\n",
    "    or does not fire with an activation of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba842b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Explain the ADALINE network model ?\n",
    "Ans: MADALINE (Many ADALINE) is a three-layer (input, hidden, output), fully connected, feed-forward artificial neural network \n",
    "    architecture for classification that uses ADALINE units in its hidden and output layers, i.e. its activation function is \n",
    "    the sign function. The three-layer network uses memistors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c29f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. What is the constraint of a simple perceptron? Why it may fail with a real-world data set ?\n",
    "Ans: The output of a perceptron can only be a binary number (0 or 1) due to the hard limit transfer function. Perceptron can \n",
    "    only be used to classify the linearly separable sets of input vectors. If input vectors are non-linear, it is not easy to \n",
    "    classify them properly.\n",
    "    Perceptron networks should be trained with adapt, which presents the input vectors to the network one at a time and makes \n",
    "    corrections to the network based on the results of each presentation. Use of adapt in this way guarantees that any linearly\n",
    "    separable problem is solved in a finite number of training presentations. Perceptrons can also be trained with the function \n",
    "    train, which is presented in the next chapter. When train is used for perceptrons, it presents the inputs to the network in\n",
    "    batches, and makes corrections to the network based on the sum of all the individual corrections. Unfortunately, there is \n",
    "    no proof that such a training algorithm converges for perceptrons. On that account the use of train for perceptrons is not \n",
    "    recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e884b688",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. What is linearly inseparable problem? What is the role of the hidden layer ?\n",
    "Ans: Clearly not all decision problems are linearly separable: they cannot be solved using a linear decision boundary. \n",
    "    Problems like these are termed linearly inseparable. XOR is a linearly inseparable problem.\n",
    "    Hidden layers allow for the function of a neural network to be broken down into specific transformations of the data. Each \n",
    "    hidden layer function is specialized to produce a defined output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2945fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. Explain XOR problem in case of a simple perceptron?\n",
    "Ans: The XOr problem is that we need to build a Neural Network (a perceptron in our case) to produce the truth table related to\n",
    "    the XOr logical operator. This is a binary classification problem. Hence, supervised learning is a better way to solve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e98a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Design a multi-layer perceptron to implement A XOR B ?\n",
    "Ans: In the field of Machine Learning, the Perceptron is a Supervised Learning Algorithm for binary classifiers. \n",
    "    or a particular choice of the weight vector $\\boldsymbol{w}$ and bias parameter $\\boldsymbol{b}$ , the model predicts output $\\boldsymbol{\\hat{y}}$ for the corresponding input vector $\\boldsymbol{x}$ . XOR logical function truth table for 2-bit binary variables, i.e, the input vector $\\boldsymbol{x} : (\\boldsymbol{x_{1}}, \\boldsymbol{x_{2}})$ and the corresponding output $\\boldsymbol{y}$ –"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0807313a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR(0, 1) = 1\n",
      "XOR(1, 1) = 0\n",
      "XOR(0, 0) = 0\n",
      "XOR(1, 0) = 1\n"
     ]
    }
   ],
   "source": [
    "# importing Python library\n",
    "import numpy as np\n",
    " \n",
    "# define Unit Step Function\n",
    "def unitStep(v):\n",
    "    if v >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    " \n",
    "# design Perceptron Model\n",
    "def perceptronModel(x, w, b):\n",
    "    v = np.dot(w, x) + b\n",
    "    y = unitStep(v)\n",
    "    return y\n",
    " \n",
    "# NOT Logic Function\n",
    "# wNOT = -1, bNOT = 0.5\n",
    "def NOT_logicFunction(x):\n",
    "    wNOT = -1\n",
    "    bNOT = 0.5\n",
    "    return perceptronModel(x, wNOT, bNOT)\n",
    "\n",
    "# AND Logic Function\n",
    "# here w1 = wAND1 = 1,\n",
    "# w2 = wAND2 = 1, bAND = -1.5\n",
    "def AND_logicFunction(x):\n",
    "    w = np.array([1, 1])\n",
    "    bAND = -1.5\n",
    "    return perceptronModel(x, w, bAND)\n",
    " \n",
    "# OR Logic Function\n",
    "# w1 = 1, w2 = 1, bOR = -0.5\n",
    "def OR_logicFunction(x):\n",
    "    w = np.array([1, 1])\n",
    "    bOR = -0.5\n",
    "    return perceptronModel(x, w, bOR)\n",
    " \n",
    "# XOR Logic Function\n",
    "# with AND, OR and NOT \n",
    "# function calls in sequence\n",
    "def XOR_logicFunction(x):\n",
    "    y1 = AND_logicFunction(x)\n",
    "    y2 = OR_logicFunction(x)\n",
    "    y3 = NOT_logicFunction(y1)\n",
    "    final_x = np.array([y2, y3])\n",
    "    finalOutput = AND_logicFunction(final_x)\n",
    "    return finalOutput\n",
    " \n",
    "# testing the Perceptron Model\n",
    "test1 = np.array([0, 1])\n",
    "test2 = np.array([1, 1])\n",
    "test3 = np.array([0, 0])\n",
    "test4 = np.array([1, 0])\n",
    " \n",
    "print(\"XOR({}, {}) = {}\".format(0, 1, XOR_logicFunction(test1)))\n",
    "print(\"XOR({}, {}) = {}\".format(1, 1, XOR_logicFunction(test2)))\n",
    "print(\"XOR({}, {}) = {}\".format(0, 0, XOR_logicFunction(test3)))\n",
    "print(\"XOR({}, {}) = {}\".format(1, 0, XOR_logicFunction(test4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014df9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Explain the single-layer feed forward architecture of ANN ?\n",
    "Ans: Feed-forward neural networks allows signals to travel one approach only, from input to output. There is no feedback\n",
    "    (loops) such as the output of some layer does not influence that same layer. Feed-forward networks tends to be simple \n",
    "    networks that associates inputs with outputs. It can be used in pattern recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808b52e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. Explain the competitive network architecture of ANN ?\n",
    "Ans: A neural network consists of three layers. The first layer is the input layer. It contains the input neurons that send \n",
    "    information to the hidden layer. The hidden layer performs the computations on input data and transfers the output to the \n",
    "    output layer. It includes weight, activation function, cost function.\n",
    "\n",
    "The connection between neurons is known as weight, which is the numerical values. The weight between neurons determines the \n",
    "learning ability of the neural network. During the learning of artificial neural networks, weight between the neuron changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece772d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "11. Consider a multi-layer feed forward neural network. Enumerate and explain steps in the backpropagation algorithm used to \n",
    "train the network ?\n",
    "Ans: Backpropagation is a supervised learning algorithm, for training Multi-layer Perceptrons (Artificial Neural Networks).\n",
    "    The steps are as follows:\n",
    "        Calculate the error – How far is your model output from the actual output.\n",
    "Minimum Error – Check whether the error is minimized or not.\n",
    "Update the parameters – If the error is huge then, update the parameters (weights and biases). After that again check the error.\n",
    "Repeat the process until the error becomes minimum.\n",
    "Model is ready to make a prediction – Once the error becomes minimum, you can feed some inputs to your model and it will \n",
    "produce the output.\n",
    "\n",
    "Step – 1: Forward Propagation\n",
    "Step – 2: Backward Propagation \n",
    "Step – 3: Putting all the values together and calculating the updated weight value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33272963",
   "metadata": {},
   "outputs": [],
   "source": [
    "12. What are the advantages and disadvantages of neural networks ?\n",
    "Ans: Advantages of Artificial Neural Networks ( ANN)\n",
    "\n",
    "Storing information on the entire network: Information such as in traditional programming is stored on the entire network, not \n",
    "    on a database. The disappearance of a few pieces of information in one place does not restrict the network from functioning. \n",
    "The ability to work with inadequate knowledge: After ANN training, the data may produce output even with incomplete information.\n",
    "    The lack of performance here depends on the importance of the missing information. \n",
    "It has fault tolerance:  Corruption of one or more cells of ANN does not prevent it from generating output. This feature makes \n",
    "    the networks fault-tolerant. \n",
    "Having a distributed memory: For ANN to be able to learn, it is necessary to determine the examples and to teach the network \n",
    "    according to the desired output by showing these examples to the network. The network's progress is directly proportional \n",
    "    to the selected instances, and if the event can not be shown to the network in all its aspects, the network can produce \n",
    "    incorrect output \n",
    "Gradual corruption:  A network slows over time and undergoes relative degradation. The network problem does not immediately \n",
    "corrode.\n",
    "Ability to train machine: Artificial neural networks learn events and make decisions by commenting on similar events. \n",
    "    \n",
    "    Disadvantages of Artificial Neural Networks (ANN)\n",
    "\n",
    "Hardware dependence:  Artificial neural networks require processors with parallel processing power, by their structure. For this\n",
    "    reason, the realization of the equipment is dependent. \n",
    "\n",
    "Unexplained functioning of the network: This is the most important problem of ANN. When ANN gives a probing solution, it does \n",
    "    not give a clue as to why and how. This reduces trust in the network. \n",
    "\n",
    "Assurance of proper network structure:  There is no specific rule for determining the structure of artificial neural networks. \n",
    "    The appropriate network structure is achieved through experience and trial and error. \n",
    "\n",
    "The difficulty of showing the problem to the network:  ANNs can work with numerical information. Problems have to be translated \n",
    "    into numerical values before being introduced to ANN. The display mechanism to be determined here will directly influence \n",
    "    the performance of the network. This depends on the user's ability. \n",
    "\n",
    "The duration of the network is unknown: The network is reduced to a certain value of the error on the sample means that the \n",
    "    training has been completed. This value does not give us optimum results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b8071",
   "metadata": {},
   "outputs": [],
   "source": [
    "13. Write short notes on any two of the following:\n",
    "1.Biological neuron\n",
    "2.ReLU function\n",
    "3.Single-layer feed forward ANN\n",
    "4.Gradient descent\n",
    "5.Recurrent networks\n",
    "Ans: Biological Neuron: The neuron is the fundamental building block of neural networks. In the biological systems, a neuron \n",
    "        is a cell just like any other cell of the body, which has a DNA code and is generated in the same way as the other \n",
    "        cells. Though it might have different DNA, the function is similar in all the organisms\n",
    "        \n",
    "    ReLU Function: The rectified linear activation function or ReLU for short is a piecewise linear function that will output \n",
    "        the input directly if it is positive, otherwise, it will output zero. It has become the default activation function for\n",
    "        many types of neural networks because a model that uses it is easier to train and often achieves better performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
